{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlpdemystified-topic-modelling-lda.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITy3IHHU95uS"
      },
      "source": [
        "# Natural Language Processing Demystified | Topic Modelling With Latent Dirichlet Allocation\n",
        "https://nlpdemystified.org<br>\n",
        "https://github.com/futuremojo/nlp-demystified<br><br>\n",
        "Course module for this demo: https://www.nlpdemystified.org/course/topic-modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aes1ZqWZTUa5"
      },
      "source": [
        "# spaCy upgrade and package installation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSVwiu4YTVDa"
      },
      "source": [
        "At the time this notebook was created, spaCy had newer releases but Colab was still using version 2.x by default. So the first step is to upgrade spaCy.\n",
        "<br><br>\n",
        "**IMPORTANT**<br>\n",
        "If you're running this in the cloud rather than a local Jupyter server on your machine, then the notebook will *timeout* after a period of inactivity. If that happens and you don't reconnect in time, you will need to upgrade spaCy again and reinstall the requisite statistical package(s).\n",
        "<br><br>\n",
        "Refer to this link on how to run Colab notebooks locally on your machine to avoid this issue:<br>\n",
        "https://research.google.com/colaboratory/local-runtimes.html\n",
        "\n",
        "---\n",
        "> **In the course video, I ran this demo on a local Jupyter server to take advantage of multiprocessing capabilities. It's not necessary but I recommend it.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VstAdWMUWvp"
      },
      "source": [
        "!pip install -U spacy==3.*\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKZgKn9TTc9Z"
      },
      "source": [
        "For topic modelling, we'll use **Gensim**, a popular topic modelling library originally authored by Radim Řehůřek. It has implementations for LDA and other models.<br>\n",
        "https://radimrehurek.com/gensim/index.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upgrade gensim in case.\n",
        "!pip install --upgrade numpy\n",
        "!pip install -U gensim==4.*"
      ],
      "metadata": {
        "id": "gRg7SM8qEY7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import random\n",
        "import spacy\n",
        "\n",
        "from gensim import models, corpora\n",
        "from gensim import similarities\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from wordcloud import WordCloud"
      ],
      "metadata": {
        "id": "YcyuLLRk9Epv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUqudgVeCfbM"
      },
      "source": [
        "# First pass at building an LDA topic model for our corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHBDR4ZqVvwY"
      },
      "source": [
        "We'll use a corpus of over 90,000 CNN news articles originally compiled for training question answering models. I lightly processed them to remove some metadata and put them on Google Drive.\n",
        "([original source](https://cs.nyu.edu/~kcho/DMQA/))\n",
        "<br><br>\n",
        "To retrieve the corpus from Google Drive, we'll use the **gdown** library which I've already installed:<br>\n",
        "https://github.com/wkentaro/gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the CNN corpus.\n",
        "!gdown 'https://drive.google.com/uc?id=122fC9XpNwFKx0ryRVKJz5MWUTzA3Vpsf'"
      ],
      "metadata": {
        "id": "kO0I2ThbauR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The corpus is one large text file with each article in the corpus separated by an *@delimiter* string. We'll split the articles and place them in a list."
      ],
      "metadata": {
        "id": "Gpu_Z5fdbYpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('cnn_articles.txt', 'r') as f:\n",
        "  articles = f.read().split('@delimiter')"
      ],
      "metadata": {
        "id": "JxGeaaj4auNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(articles))\n",
        "print(articles[0])"
      ],
      "metadata": {
        "id": "9QNyQo5gauIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this demo, we'll use a subset of the articles to speed things up but feel free to change the dataset size."
      ],
      "metadata": {
        "id": "1lKZEP-J02TA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_SIZE = 20000\n",
        "dataset = articles[:DATASET_SIZE]"
      ],
      "metadata": {
        "id": "YSfxX4tlbpa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just like in the [Text Classification with Naive Bayes](https://github.com/futuremojo/nlp-demystified/blob/main/notebooks/nlpdemystified_classification_naive_bayes.ipynb) demo, we'll start off with a *blank* tokenizer with no further pipeline components to see if that's good enough.\n",
        "<br><br>\n",
        "We'll filter out punctuations, newlines, and any tokens containing non-alphabetic characters."
      ],
      "metadata": {
        "id": "qLkJz7BS6q-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.blank('en')\n",
        "\n",
        "def basic_filter(tokenized_doc):\n",
        "  return [t.text for t in tokenized_doc if\n",
        "          not t.is_punct and \\\n",
        "          not t.is_space and \\\n",
        "          t.is_alpha]"
      ],
      "metadata": {
        "id": "g6XVBLIl0FkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this demo, we'll leverage spaCy's **nlp.pipe** function which can process a corpus as a batch (or a series of batches) and use multiple processes. Here, we'll process our dataset as a batch across multiple processes, then run the tokenized **doc** objects through the *basic_filter* function. You can adjust **NUM_PROCESS** as you wish.<br><br>\n",
        "Take a look at these link for ways to further optimize spaCy's pipeline:<br>\n",
        "https://spacy.io/usage/processing-pipelines#processing<br>\n",
        "https://spacy.io/api/language#pipe<br><br>\n",
        "YouTube video from spaCy on using **nlp.pipe**: [Speed up spaCy pipelines via `nlp.pipe` - spaCy shorts](https://www.youtube.com/watch?v=OoZ-H_8vRnc)<br>\n",
        "Tuning **nlp.pipe**: https://stackoverflow.com/questions/65850018/processing-text-with-spacy-nlp-pipe"
      ],
      "metadata": {
        "id": "6siL9mNJxqix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_PROCESS = 4"
      ],
      "metadata": {
        "id": "L1SVzXUzxtBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "tokenized_articles = list(map(basic_filter, nlp.pipe(dataset, n_process=NUM_PROCESS)))"
      ],
      "metadata": {
        "id": "nGYhfDXcz9_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYNK7Nd-cLsZ"
      },
      "source": [
        "print(tokenized_articles[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkopX2P4UqDK"
      },
      "source": [
        "To start off, we'll go with 20 topics. With most topic models including LDA, there isn't a clear recipe on how to pick the optimal number of topics. The nature and composition of the data (e.g. average length of each document) has a major impact on how many topics are *interpretable* by a human. Often, it's best to go with something reasonable to begin with and then try different topic numbers.<br><br>For this corpus, I'm going with 20 topics which is a small amount relative to the corpus size, but my reasoning is that since this is a general mainstream news corpus, the topics themselves are going to be fairly broad."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9RbTz3OXTuM"
      },
      "source": [
        "NUM_TOPICS = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgCbr9SJZxDQ"
      },
      "source": [
        "After tokenizing our text, the first step with Gensim is to construct a **Dictionary** mapping words to integer IDs.<br>\n",
        "https://radimrehurek.com/gensim/corpora/dictionary.html<br><br>\n",
        "This is similar to the *fit* step we took with scikit-learn's vectorizers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP2db-H8cUwb"
      },
      "source": [
        "# Build a Dictionary of word<-->id mappings.\n",
        "%%time\n",
        "dictionary = corpora.Dictionary(tokenized_articles)\n",
        "\n",
        "sample_token = 'news'\n",
        "print(f'Id for \\'{sample_token}\\' token: {dictionary.token2id[sample_token]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyAHgUxEaXVf"
      },
      "source": [
        "The next step is to create a frequency bag-of-words from each article using the **dictionary**'s *doc2bow* method. This is similar to the *transform* step from scikit-learn's vectorizers.<br>\n",
        "https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary.doc2bow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYpRy9W6cWAK"
      },
      "source": [
        "%%time\n",
        "corpus_bow = [dictionary.doc2bow(article) for article in tokenized_articles]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD9khr0RbBTq"
      },
      "source": [
        "Finally, we'll generate our base LDA model. Gensim's LDA model has a large number of optional parameters but for now, we'll keep it simple.<br>\n",
        "https://radimrehurek.com/gensim/models/ldamodel.html?highlight=lda#module-gensim.models.ldamodel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP0MS3n7dxE_"
      },
      "source": [
        "%%time\n",
        "lda_model = models.LdaModel(corpus=corpus_bow, num_topics=NUM_TOPICS, id2word=dictionary, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ecFL_MSb9wp"
      },
      "source": [
        "Once our model is generated, we can view the topics inferred. By default, the model's *print_topics* method shows the top 20 topics and each topic's ten most significant words.<br>\n",
        "https://radimrehurek.com/gensim/models/ldamodel.html?highlight=lda#gensim.models.ldamodel.LdaModel.print_topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFTFPOb4eKUi"
      },
      "source": [
        "lda_model.print_topics()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYmfb5YGcSP8"
      },
      "source": [
        "The first pass is pretty awful. The topics are dominated by stop words such that they essentially look all the same. Let's see if we can do better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kf0X-w47svTF"
      },
      "source": [
        "# Improving preprocessing for better results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkI5wxWccz8U"
      },
      "source": [
        "For our next attempt, we'll\n",
        "- remove stop words using the default spaCy stopword list. Given this is a corpus of news articles, there may be other stop words to consider such as salutations (\"Mr\", \"Mrs\"), and words related to quotes and thoughts (\"say\", \"think\"). But for this, we'll stick to defaults unless we see reason to do otherwise.\n",
        "- consider only the words the spaCy tagger flags as *nouns, verbs,* and *adjectives*. Including words with only certain POS tags is a common approach to improving topic models.\n",
        "- take the lemma."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
        "\n",
        "def improved_filter(tokenized_doc):\n",
        "  return [t.lemma_ for t in tokenized_doc if\n",
        "          t.is_alpha and \\\n",
        "          not t.is_punct and \\\n",
        "          not t.is_space and \\\n",
        "          not t.is_stop and \\\n",
        "          t.pos_ in ['NOUN', 'VERB', 'ADJ']]"
      ],
      "metadata": {
        "id": "i1emkEmz1pYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLqKeoy9FQED"
      },
      "source": [
        "# We'll need to retokenize everything and rebuild the BOWs. Because we're now\n",
        "# using the POS tagger, this will take longer. The \"w_pos\" in the variable \n",
        "# names below just means \"with part-of-speech\".\n",
        "%%time\n",
        "tokenized_articles_w_pos = list(map(improved_filter, nlp.pipe(dataset, n_process=NUM_PROCESS)))\n",
        "dictionary_w_pos = corpora.Dictionary(tokenized_articles_w_pos)\n",
        "corpus_bow_w_pos = [dictionary_w_pos.doc2bow(article) for article in tokenized_articles_w_pos]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sNd_PZypu13"
      },
      "source": [
        "%%time\n",
        "lda_model = models.LdaModel(corpus=corpus_bow_w_pos, num_topics=NUM_TOPICS, id2word=dictionary_w_pos, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG5iFkrQqyx5"
      },
      "source": [
        "lda_model.print_topics()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ckwYRIqgOtB"
      },
      "source": [
        "This is better but there are still a few low-signal words dominating topics such as \"said\" lemmatized to \"say\" which makes sense for a news corpus. Perhaps trimming the vocabulary and tuning the model parameters themselves can lead to something more interpretable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_8oBuWxvqdl"
      },
      "source": [
        "# Trimming low- and high-frequency words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFDI1BSLgxJw"
      },
      "source": [
        "One thing we can try is filtering out rare and common tokens.\n",
        "https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary.filter_extremes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YQctCWVhnL6"
      },
      "source": [
        "# The size of the dictionary before filtering.\n",
        "len(dictionary_w_pos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8tzEnZKyfeC"
      },
      "source": [
        "The filtering is a bit idiosyncratic. The lower bound is an *absolute* number, and the upper bound is a *percentage*. Here, we're saying filter out words which occur in fewer than N documents and more than M% of the documents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyCG8tLIp2QC"
      },
      "source": [
        "dictionary_w_pos.filter_extremes(no_below=5, no_above=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AvypKffhpyR"
      },
      "source": [
        "# The size of the dictionary after filtering.\n",
        "len(dictionary_w_pos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWomtBFzhuO5"
      },
      "source": [
        "# Rebuild bag of words.\n",
        "corpus_bow_w_pos_filtered = [dictionary_w_pos.doc2bow(article) for article in tokenized_articles_w_pos]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVtALC9yYB9Z"
      },
      "source": [
        "This time, we're passing additional arguments when building the model. *alpha* is the prior on the document-topic distribution, and *eta* is the prior on the topic-word distribution (this was *beta* in the slides), and *passes* is the number of complete passes through the corpus during training.<br>\n",
        "https://radimrehurek.com/gensim/models/ldamodel.html?highlight=lda#module-gensim.models.ldamodel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8_-mIdSvqUc"
      },
      "source": [
        "%%time\n",
        "lda_model = models.ldamodel.LdaModel(corpus=corpus_bow_w_pos_filtered,\n",
        "                                     id2word=dictionary_w_pos,\n",
        "                                     num_topics=NUM_TOPICS,\n",
        "                                     passes=10,\n",
        "                                     alpha='auto',\n",
        "                                     eta='auto',\n",
        "                                     random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iR2xCvNZvqDn"
      },
      "source": [
        "lda_model.print_topics()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With improved filtering and low- and high-frequency words trimmed, we can see the topic-word distributions containing certain themes such as crime, travel, entertainment, etc.<br><br>\n",
        "**NOTE:** Remember that the topic model doesn't label topics for us. It just converges on collections of terms that likely form topics."
      ],
      "metadata": {
        "id": "o3dM-87PxPSY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We set the training algorithm to learn priors for *alpha* and *eta*."
      ],
      "metadata": {
        "id": "HVipraNhL2fX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(lda_model.alpha)\n",
        "print(lda_model.eta)"
      ],
      "metadata": {
        "id": "5aimFUJGw4gT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *alpha* and *eta* values the training algorithm arrived at are well below 1. This translates to most articles being dominated by one or just a few topics, and most topics being dominated by a handful of words."
      ],
      "metadata": {
        "id": "Aj86WOUlL0zj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auRQbV8Ajaz8"
      },
      "source": [
        "We can look at the topic distribution comprising a given article using the model's *get_document_topics* method.<br>\n",
        "https://radimrehurek.com/gensim/models/ldamodel.html#gensim.models.ldamodel.LdaModel.get_document_topics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article_idx = 0\n",
        "print(dataset[article_idx][:300])"
      ],
      "metadata": {
        "id": "7naCCCX1Nb2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Return topic distribution for an article sorted by probability.\n",
        "topics = sorted(lda_model.get_document_topics(corpus_bow_w_pos_filtered[article_idx]), key=lambda tup: tup[1])[::-1]\n",
        "topics"
      ],
      "metadata": {
        "id": "DrGy3dO019LL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can get the top words (10 by default) representing a topic using the model's *show_topic* method.\n",
        "https://radimrehurek.com/gensim/models/ldamodel.html#gensim.models.ldamodel.LdaModel.show_topic"
      ],
      "metadata": {
        "id": "85ztp46j13OL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View the words of the top topic from the previous article.\n",
        "lda_model.show_topic(topics[0][0])"
      ],
      "metadata": {
        "id": "aoA0ATU016Tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the words of the second-most prevalent topic from the previous article.\n",
        "lda_model.show_topic(topics[1][0])"
      ],
      "metadata": {
        "id": "oKJ9pvL2HQ3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function below takes a document index and returns a **DataFrame** containing:\n",
        "1. the topics comprising the document up to a minimum probability.\n",
        "2. the top words of each topic.\n",
        "<br>\n",
        "\n",
        "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html"
      ],
      "metadata": {
        "id": "VbsiukJ414XD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_topics(article_idx, min_topic_prob):\n",
        "\n",
        "  # Sort from highest to lowest topic probability.\n",
        "  topic_prob_pairs = sorted(lda_model.get_document_topics(corpus_bow_w_pos_filtered[article_idx],\n",
        "                                                          minimum_probability=min_topic_prob),\n",
        "                            key=lambda tup: tup[1])[::-1]\n",
        "\n",
        "  word_prob_pairs = [lda_model.show_topic(pair[0]) for pair in topic_prob_pairs]\n",
        "  topic_words = [[pair[0] for pair in collection] for collection in word_prob_pairs]\n",
        "\n",
        "  data = {\n",
        "      'Major Topics': topic_prob_pairs,\n",
        "      'Topic Words': topic_words\n",
        "  }\n",
        "\n",
        "  return pd.DataFrame(data)\n"
      ],
      "metadata": {
        "id": "o8F3dsBk2Oh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('max_colwidth', 600)\n",
        "snippet_length = 300\n",
        "min_topic_prob = 0.25\n",
        "\n",
        "article_idx = 1\n",
        "print(dataset[article_idx][:snippet_length])\n",
        "get_top_topics(article_idx, min_topic_prob)"
      ],
      "metadata": {
        "id": "y7HwvNlH3KNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_idx = 10\n",
        "print(dataset[article_idx][:snippet_length])\n",
        "get_top_topics(article_idx, min_topic_prob)"
      ],
      "metadata": {
        "id": "RgbK19OAYD6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_idx = 100\n",
        "print(dataset[article_idx][:snippet_length])\n",
        "get_top_topics(article_idx, min_topic_prob)"
      ],
      "metadata": {
        "id": "ucpGCL0cYD2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_idx = 1000\n",
        "print(dataset[article_idx][:snippet_length])\n",
        "get_top_topics(article_idx, min_topic_prob)"
      ],
      "metadata": {
        "id": "KzeM3QEbYDyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_idx = 10000\n",
        "print(dataset[article_idx][:snippet_length])\n",
        "get_top_topics(article_idx, 0.25)"
      ],
      "metadata": {
        "id": "vT5gxoP9YDuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCr_9vWPvuU9"
      },
      "source": [
        "The results of this model look the best so far and we can see a human-interpretable link between the distribution of topics in a document, the distribution of words in each topic, and the content of the document itself."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRCf02nVvpfW"
      },
      "source": [
        "# Evaluation and Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TXlK5gebUjB"
      },
      "source": [
        "## Measuring topic models with coherence.\n",
        "\n",
        "If a topic is a mixture of particular words, then one way to measure how semantically coherent a topic is to calculate co-occurrence among the words. That is, how often the top words in a topic co-occur together among the documents versus how often they occur independently.\n",
        "\n",
        "Gensim's **Coherence Model** offers coherence implemented as a pipeline:<br>\n",
        "https://radimrehurek.com/gensim/models/coherencemodel.html\n",
        "<br>\n",
        "<br>\n",
        "See this paper for a detailed description of the pipeline as well as different co-occurence measures proposed:<br>\n",
        "http://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf\n",
        "<br>\n",
        "<br>\n",
        "Topic model evaluation is a difficult subject with no clear quantitative approach and is still debated. A higher (or lower score depending on the measure) doesn't necessarily translate to a higher *qualitative* model. That is, the score a human would give looking at the topic words and how interpretable they are.<br><br>\n",
        "It's possible to favour a poorer scoring model because it serves a particular purpose better. Perhaps it's better to score the effectiveness of topic models based on performance in downstream tasks? See these videos for the problems with quantitative topic model evaluation:<br>\n",
        "[Matti Lyra - Evaluating Topic Models](https://www.youtube.com/watch?v=UkmIljRIG_M)<br>\n",
        "[Is Topic Model Evaluation Broken? The Incoherence of Coherence](https://www.youtube.com/watch?v=4KO2TO_cm2I)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHBp-ZazNZRJ"
      },
      "source": [
        "%%time\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=tokenized_articles_w_pos, dictionary=dictionary_w_pos, coherence='u_mass')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kfunq1Su8d1r"
      },
      "source": [
        "## Human evaluation\n",
        "Because the quantitative metrics aren't entirely correlated with quality, human judgment still plays a large role in topic model evaluation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crPK6zKfC1gS"
      },
      "source": [
        "We can get someone to look at the topic words to see how interpretable they are. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are also subjective tests like **word intrusion** and **topic intrusion**.\n",
        "<br><br>\n",
        "**Word intrusion** is taking words which belong to a topic, injecting a word from another topic into the collection, and seeing whether a human can easily identify the intruder word. The more easily the intruder word is spotted, the more well-formed the topic. For example, which word doesn't belong in this topic?<br>\n",
        "*{apple, lemon, tomato, horse, grape}*"
      ],
      "metadata": {
        "id": "GRMHpNksr0bQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYfEicOH8d1t"
      },
      "source": [
        "We can also visualize them with word clouds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qY6uzIW8d1t"
      },
      "source": [
        "def render_word_cloud(model, rows, cols, max_words):\n",
        "  word_cloud = WordCloud(background_color='white', max_words=max_words, prefer_horizontal=1.0)\n",
        "  fig, axes = plt.subplots(rows, cols, figsize=(15,15))\n",
        "\n",
        "  for i, ax in enumerate(axes.flatten()):\n",
        "      fig.add_subplot(ax)\n",
        "      topic_words = dict(model.show_topic(i))\n",
        "      word_cloud.generate_from_frequencies(topic_words)\n",
        "      plt.gca().imshow(word_cloud, interpolation='bilinear')\n",
        "      plt.gca().set_title('Topic {id}'.format(id=i))\n",
        "      plt.gca().axis('off')\n",
        "\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3e6HjGtzNnG"
      },
      "source": [
        "# Here we'll visualize the first nine topics.\n",
        "render_word_cloud(lda_model, 3, 3, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpBxrPcGEOcN"
      },
      "source": [
        "# Finding similar documents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJtKEzTE8TSE"
      },
      "source": [
        "Gensim has a **similarities** module which can build an index for a given set of documents. Here, we're using **MatrixSimilarity** which computes cosine similarity across a corpus and stores them in an index.<br>\n",
        "https://radimrehurek.com/gensim/similarities/docsim.html#gensim.similarities.docsim.MatrixSimilarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq9EYQJWkib2"
      },
      "source": [
        "lda_index = similarities.MatrixSimilarity(lda_model[corpus_bow_w_pos_filtered], num_features=len(dictionary_w_pos))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHorc8fN9VHu"
      },
      "source": [
        "Here's a utility function to help retrieve the *first_m_words* of the *top_n* most similar documents. If you're curious about the *\\_\\_getitem\\__* method on the LDA Model class, you can find the code here:<br>\n",
        "https://github.com/RaRe-Technologies/gensim/blob/master/gensim/models/ldamodel.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6hIGoVYF6Rb"
      },
      "source": [
        "def get_similar_articles(index, model, article_bow, top_n=5, first_m_words=300):\n",
        "  # model[article_bow] retrieves the topic distribution for the BOW.\n",
        "  # index[model[article_bow] compares the topic distribution for the BOW against the similarity index previously computed.\n",
        "  similar_docs = index[model[article_bow]]\n",
        "  top_n_docs = sorted(enumerate(similar_docs), key=lambda item: -item[1])[1:top_n+1]\n",
        "  \n",
        "  # Return a list of tuples with each tuple: (article id, similarity score, first_m_words of article)\n",
        "  return list(map(lambda entry: (entry[0], entry[1], articles[entry[0]][:first_m_words]), top_n_docs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4GV6jxI-Q8i"
      },
      "source": [
        "article_idx = 0\n",
        "print(dataset[article_idx][:snippet_length], '\\n')\n",
        "get_similar_articles(lda_index, lda_model, corpus_bow_w_pos_filtered[article_idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_idx = 10\n",
        "print(dataset[article_idx][:snippet_length], '\\n')\n",
        "get_similar_articles(lda_index, lda_model, corpus_bow_w_pos_filtered[article_idx])"
      ],
      "metadata": {
        "id": "d6rlTxY5zlCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_idx = 100\n",
        "print(dataset[article_idx][:snippet_length], '\\n')\n",
        "get_similar_articles(lda_index, lda_model, corpus_bow_w_pos_filtered[article_idx])"
      ],
      "metadata": {
        "id": "JQyVGB1Kzk7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8eWhXxhBEl7"
      },
      "source": [
        "We can also query for documents similar to new, unseen documents. Below are short, actual blurbs from 2021 involving stock options and crime. Keep in mind that if this were a really old news corpus, then excerpts about cryptocurrencies and social media probably won't lead to good matches. This is another aspect to keep in mind when thinking about your data and use cases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs4DF3CqODIp"
      },
      "source": [
        "test_article = \"Capricorn Business Acquisitions Inc. (TSXV: CAK.H) (the “Company“) is pleased to announce that its board has approved the issuance of 70,000 stock options (“Stock Options“) to directors on April 19, 2020.\"\n",
        "\n",
        "article_tokens = list(map(improved_filter, [nlp(test_article)]))[0]\n",
        "article_bow = dictionary_w_pos.doc2bow(article_tokens)\n",
        "get_similar_articles(lda_index, lda_model, article_bow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_article = \"DEA agent sentenced to 12 years in prison for conspiring with Colombian drug cartel.\"\n",
        "\n",
        "article_tokens = list(map(improved_filter, [nlp(test_article)]))[0]\n",
        "article_bow = dictionary_w_pos.doc2bow(article_tokens)\n",
        "get_similar_articles(lda_index, lda_model, article_bow)"
      ],
      "metadata": {
        "id": "NpejaKM51Sos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMh0xLVmuKwW"
      },
      "source": [
        "# Closing Thoughts and things to explore.\n",
        "- Gensim infers topic and word distributions through [Variational Bayes (VB)](https://en.wikipedia.org/wiki/Variational_Bayesian_methods), not Gibbs Sampling. From the topics I've seen, Gibbs Sampling tends to lead to more interpretable topics, but VB is faster and Gensim offers the additional benefits of streaming documents, online learning, and training across a cluster of machines.\n",
        "- Another topic modelling library, [Mallet](http://mallet.cs.umass.edu/), infers through Gibbs Sampling but is Java-based. Unfortunately, Gensim 4.0+ no longer offers a wrapper around Mallet. But if you're comfortable with Java, it may be worth exploring.\n",
        "- Scikit-learn offers an [LDA model](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html). Maybe as an exercise, try using that LDA model on the [20 Newsgroups](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html) dataset (or ideally, a dataset with longer documents).\n",
        "- [pyLDAvis](https://github.com/bmabey/pyLDAvis) is another means of visualizing topic models. You can see it in action in this [notebook](https://nbviewer.jupyter.org/github/bmabey/pyLDAvis/blob/master/notebooks/pyLDAvis_overview.ipynb). See if you can get it working on your own topic model.\n",
        "- LDA tends to work better on longer documents, and whether a topic model is \"good\" depends on your use case rather than strictly on a quantitative metric."
      ]
    }
  ]
}
